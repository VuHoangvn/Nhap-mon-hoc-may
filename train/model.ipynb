{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyvi import ViTokenizer, ViPosTagger, ViUtils\n",
    "from CocCocTokenizer import PyTokenizer\n",
    "T = PyTokenizer(load_nontone_data=True)\n",
    "# print(T.word_tokenize(\"tot  san pham giong hinhda dep\", tokenize_option=0))\n",
    "# print(ViTokenizer.tokenize(\"xin chào, tôi là người Việt Nam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = []\n",
    "with open('stopword.txt') as fp:\n",
    "    for row in fp:\n",
    "        stop_word.append(row.strip())\n",
    "stop_word = set(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceCompositUnicode(str):\n",
    "    str = str.replace('à', 'à')\n",
    "    str = str.replace('ả', 'ả')\n",
    "    str = str.replace('ã', 'ã')\n",
    "    str = str.replace('á', 'á')\n",
    "    str = str.replace('ạ', 'ạ')\n",
    "    str = str.replace('ấ', 'ấ')\n",
    "    str = str.replace('ầ', 'ầ')\n",
    "    str = str.replace('ậ', 'ậ')\n",
    "    str = str.replace('ẩ', 'ẩ')\n",
    "    str = str.replace('ẫ', 'ẫ')\n",
    "    str = str.replace('ắ', 'ắ')\n",
    "    str = str.replace('ằ', 'ằ')\n",
    "    str = str.replace('ặ', 'ặ')\n",
    "    str = str.replace('ẳ', 'ẳ')\n",
    "    str = str.replace('ẵ', 'ẵ')\n",
    "    str = str.replace('è', 'è')\n",
    "    str = str.replace('ẻ', 'ẻ')\n",
    "    str = str.replace('ẽ', 'ẽ')\n",
    "    str = str.replace('é', 'é')\n",
    "    str = str.replace('ẹ', 'ẹ')\n",
    "    str = str.replace('ế', 'ế')\n",
    "    str = str.replace('ề', 'ề')\n",
    "    str = str.replace('ệ', 'ệ')\n",
    "    str = str.replace('ể', 'ể')\n",
    "    str = str.replace('ễ', 'ễ')\n",
    "    str = str.replace('ì', 'ì')\n",
    "    str = str.replace('ỉ', 'ỉ')\n",
    "    str = str.replace('ĩ', 'ĩ')\n",
    "    str = str.replace('í', 'í')\n",
    "    str = str.replace('ị', 'ị')\n",
    "    str = str.replace('ò', 'ò')\n",
    "    str = str.replace('ỏ', 'ỏ')\n",
    "    str = str.replace('õ', 'õ')\n",
    "    str = str.replace('ó', 'ó')\n",
    "    str = str.replace('ọ', 'ọ')\n",
    "    str = str.replace('ố', 'ố')\n",
    "    str = str.replace('ồ', 'ồ')\n",
    "    str = str.replace('ộ', 'ộ')\n",
    "    str = str.replace('ổ', 'ổ')\n",
    "    str = str.replace('ỗ', 'ỗ')\n",
    "    str = str.replace('ớ', 'ớ')\n",
    "    str = str.replace('ờ', 'ờ')\n",
    "    str = str.replace('ợ', 'ợ')\n",
    "    str = str.replace('ở', 'ở')\n",
    "    str = str.replace('ỡ', 'ỡ')\n",
    "    str = str.replace('ù', 'ù')\n",
    "    str = str.replace('ủ', 'ủ')\n",
    "    str = str.replace('ũ', 'ũ')\n",
    "    str = str.replace('ú', 'ú')\n",
    "    str = str.replace('ụ', 'ụ')\n",
    "    str = str.replace('ứ', 'ứ')\n",
    "    str = str.replace('ừ', 'ừ')\n",
    "    str = str.replace('ự', 'ự')\n",
    "    str = str.replace('ử', 'ử')\n",
    "    str = str.replace('ữ', 'ữ')\n",
    "    str = str.replace('ỳ', 'ỳ')\n",
    "    str = str.replace('ỷ', 'ỷ')\n",
    "    str = str.replace('ỹ', 'ỹ')\n",
    "    str = str.replace('ý', 'ý')\n",
    "    str = str.replace('ỵ', 'ỵ')\n",
    "    return str\n",
    "\n",
    "def removeSpecialCharacter(str):\n",
    "    # Loai bo ki tu dac biet\n",
    "    str = re.sub(r'[^0-9a-zăâđêôơưàảãáạấầậẩẫắằặẳẵèẻẽéẹếềệểễìỉĩíịòỏõóọốồộổỗớờợởỡùủũúụứừựửữỳỷỹýỵ,\\s\\*]+', ' ',str)\n",
    "    # Xoa bo khoang trang dai\n",
    "    str = re.sub(' {2,}', ' ', str)\n",
    "    return str\n",
    "\n",
    "def replaceAcronym(str):\n",
    "    # mot so tu viet tat\n",
    "    # 1*->1 sao, 2*-> 2 sao,...\n",
    "    str = re.sub('(^| )([0-9])\\*($| )', r'\\1sao\\2', str)\n",
    "    # 1sao -> 1 sao, 2sao -> 2 sao, ...\n",
    "    str = re.sub('(^| )([0-9])sao($| )', r'\\1sao\\2', str)\n",
    "    # * -> sao\n",
    "    str = re.sub(\"(^| )\\*($| )\", r\"\\1sao\\2\", str)\n",
    "    # s -> sao\n",
    "    str = re.sub(\"(^| )s($| )\", r\"\\1sao\\2\", str)\n",
    "    str = re.sub(\"(^| )sp($| )\", r\"\\1sản phẩm\\2\", str)\n",
    "    str = re.sub(\"(^| )rat($| )\", r\"\\1rất\\2\", str)\n",
    "    str = re.sub(\"(^| )dang($| )\", r\"\\1đáng\\2\", str)\n",
    "    str = re.sub(\"(^| )nhiu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )nhìu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )nhieu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )tot($| )\", r\"\\1tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )tôt($| )\", r\"\\1tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )muot($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )muọt($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )mươt($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )may($| )\", r\"\\1máy\\2\", str)\n",
    "    str = re.sub(\"(^| )tr($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )ae($| )\", r\"\\1anh em\\2\", str)\n",
    "    str = re.sub(\"(^| )đc($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )dc($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )dk($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )đk($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )k($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )ko($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )kg($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )kh($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )hk($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )khg($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )r($| )\", r\"\\1rồi\\2\", str)\n",
    "    str = re.sub(\"(^| )m($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mh($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mih($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mìh($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mk($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mik($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )bh($| )\", r\"\\1bao giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )h($| )\", r\"\\1giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )jo($| )\", r\"\\1giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )z($| )\", r\"\\1vậy\\2\", str)\n",
    "    str = re.sub(\"(^| )j($| )\", r\"\\1gì\\2\", str)\n",
    "    str = re.sub(\"(^| )cx($| )\", r\"\\1cũng\\2\", str)\n",
    "    str = re.sub(\"(^| )vs($| )\", r\"\\1với\\2\", str)\n",
    "    str = re.sub(\"(^| )ah($| )\", r\"\\1à\\2\", str)\n",
    "    str = re.sub(\"(^| )ak($| )\", r\"\\1à\\2\", str)\n",
    "    str = re.sub(\"(^| )ntn($| )\", r\"\\1như thế nào\\2\", str)\n",
    "    str = re.sub(\"(^| )lm($| )\", r\"\\1làm\\2\", str)\n",
    "    str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )t2($| )\", r\"\\1thứ 2\\2\", str)\n",
    "    str = re.sub(\"(^| )cn($| )\", r\"\\1chủ nhật\\2\", str)\n",
    "    str = re.sub(\"(^| )t3($| )\", r\"\\1thứ 3\\2\", str)\n",
    "    str = re.sub(\"(^| )t4($| )\", r\"\\1thứ 4\\2\", str)\n",
    "    str = re.sub(\"(^| )t5($| )\", r\"\\1thứ 5\\2\", str)\n",
    "    str = re.sub(\"(^| )t6($| )\", r\"\\1thứ 6\\2\", str)\n",
    "    str = re.sub(\"(^| )t7($| )\", r\"\\1thứ 7\\2\", str)\n",
    "    str = re.sub(\"(^| )mn($| )\", r\"\\1mọi người\\2\", str)\n",
    "    str = re.sub(\"(^| )good($| )\", r\"\\1rất_tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )5 sao($| )\", r\"\\1năm_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )năm sao($| )\", r\"\\1năm_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )4 sao($| )\", r\"\\1bốn_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )bốn sao($| )\", r\"\\1bốn_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )3 sao($| )\", r\"\\1ba_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )ba sao($| )\", r\"\\1ba_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )2 sao($| )\", r\"\\1hai_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )hai sao($| )\", r\"\\1hai_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )1 sao($| )\", r\"\\1một_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )một sao($| )\", r\"\\1một_sao\\2\", str)\n",
    "    str = re.sub(\"(^| )ok($| )\", r\"\\1rất_tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )e($| )\", r\"\\1em\\2\", str)\n",
    "    str = re.sub(\"(^| )t($| )\", r\"\\1tôi\\2\", str)\n",
    "    str = re.sub(\"(^| )thikkk($| )\", r\"\\1thích\\2\", str)\n",
    "    str = re.sub(\"(^| )thik($| )\", r\"\\1thích\\2\", str)\n",
    "    str = re.sub(\"(^| )cx($| )\", r\"\\1cũng\\2\", str)\n",
    "    str = re.sub(\"(^| )deep($| )\", r\"\\1đẹp\\2\", str)\n",
    "    str = re.sub(\"(^| )đepj($| )\", r\"\\1đẹp\\2\", str)\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def preprocess(str):\n",
    "    # to lower case\n",
    "    str = str.lower()\n",
    "    # remove punctuation\n",
    "    str = str.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    # remove white spaces\n",
    "    str = str.strip()\n",
    "    str = re.sub(' +', ' ', str)\n",
    "    str = replaceCompositUnicode(str)\n",
    "    str = removeSpecialCharacter(str)\n",
    "    str = replaceAcronym(str)\n",
    "#     # to remove number\n",
    "#     str = re.sub(r'\\d+','', str)\n",
    "    # tokenize by pyvi\n",
    "    str = ViTokenizer.tokenize(str)\n",
    "    # tokenize by coccoctokenizer\n",
    "#     print(T.word_tokenize(str, tokenize_option=0))\n",
    "#     str = unidecode(str)\n",
    "    \n",
    "    # tokenize by nltk\n",
    "#     tknzr = TweetTokenizer()\n",
    "#     str = tknzr.tokenize(str)\n",
    "#     print(str)\n",
    "    # # remove stopword\n",
    "    str = str.split()\n",
    "    str = [i for i in str if not i in stop_word]\n",
    "    str = ' '.join(str)\n",
    "#     enhance feature\n",
    "#     j = 0\n",
    "#     n_s = \"\"\n",
    "#     k = int(len(str)/3 - 1) * 3\n",
    "#     for i in range(3,k, 3):\n",
    "#         n_s += str[j:i] + \" \"\n",
    "#         j = i\n",
    "#     n_s += str[k:]\n",
    "    \n",
    "    return str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(xs, ys):\n",
    "    freqs = Counter(ys)\n",
    "    max_allowable = freqs.most_common()[-1][1]\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "star= []\n",
    "review = []\n",
    "# with open('data_final2.csv') as csv_file:\n",
    "#     for row in csv_file:\n",
    "#         row = row.split('<fff>')\n",
    "#         star.append(row[0])\n",
    "#         review.append(preprocess(row[1]))\n",
    "\n",
    "with open('train.txt', 'r') as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        star.append(line[0])\n",
    "        review.append(preprocess(line[2:]))\n",
    "        line = fp.readline()\n",
    "\n",
    "# with open('bag_text.txt', 'r') as csv_file:\n",
    "#     i = 0\n",
    "#     for row in csv_file:\n",
    "#         row = row.split('<fff>')\n",
    "#         star.append(row[0])\n",
    "#         review.append(preprocess(row[1]))\n",
    "\n",
    "\n",
    "#         i += 1\n",
    "# #         print(i)\n",
    "#         if(i == 3000):\n",
    "# #             break\n",
    "# for i in range(1, 5):\n",
    "#     filename = \"{}_star.txt\".format(i)\n",
    "#     with open(filename, 'r') as fp:\n",
    "#         line = fp.readline()\n",
    "#         j = 0\n",
    "#         while j < 500:\n",
    "#             star.append('{}'.format(i))\n",
    "#             review.append(preprocess(line))\n",
    "#             line = fp.readline() \n",
    "#             j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review, star = balance_classes(review, star)\n",
    "X_train, X_test, y_train, y_test = train_test_split(review, star, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'5': 185, '4': 85, '3': 41, '2': 9, '1': 15})"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6606060606060606\n",
      "[[ 4  0  1  2  9]\n",
      " [ 0  1  0  2  2]\n",
      " [ 0  0  5  4 11]\n",
      " [ 0  0  0 16 18]\n",
      " [ 0  0  0  7 83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#Train and evaluate the model\n",
    "# vect = CountVectorizer().fit(X_train)\n",
    "vect = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "clfrNB = MultinomialNB(alpha = 0.1)\n",
    "clfrNB.fit(X_train_vectorized, y_train)\n",
    "preds = clfrNB.predict(vect.transform(X_test))\n",
    "score = accuracy_score(y_test, preds)\n",
    "print(score)\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6909090909090909\n",
      "[[ 7  0  2  1  6]\n",
      " [ 0  1  0  1  3]\n",
      " [ 0  0  9  1 10]\n",
      " [ 0  0  0 18 16]\n",
      " [ 0  0  1 10 79]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "vectors1 = vectorizer.transform(X_test)\n",
    "    #     return vectors\n",
    "\n",
    "    # def fit(self):\n",
    "        # vectors = self.tfidf()\n",
    "classifier = LinearSVC()\n",
    "        # train the classifier\n",
    "classifier.fit(vectors, y_train)\n",
    "        # return classifier\n",
    "# vectors1 = vectorizer.transform(x_test)\n",
    "predict = classifier.predict(vectors1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac = accuracy_score(y_test, predict)\n",
    "print(ac)\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6060606060606061\n",
      "[[ 0  0  0  0 16]\n",
      " [ 0  0  0  1  4]\n",
      " [ 0  0  3  0 17]\n",
      " [ 0  0  0 11 23]\n",
      " [ 0  0  0  4 86]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.703030303030303\n",
      "[[ 7  0  2  3  4]\n",
      " [ 0  2  0  1  2]\n",
      " [ 0  0 10  2  8]\n",
      " [ 0  0  1 23 10]\n",
      " [ 0  0  2 14 74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
