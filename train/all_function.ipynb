{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from pyvi import ViTokenizer, ViPosTagger, ViUtils\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        stop_word = []\n",
    "        with open('stopword.txt') as fp:\n",
    "            for row in fp:\n",
    "                stop_word.append(row.strip())\n",
    "        stop_word = set(stop_word)\n",
    "        self.stop_word = stop_word\n",
    "        return\n",
    "    @staticmethod\n",
    "    def readStopWord(self):\n",
    "        stop_word = []\n",
    "        with open('stopword.txt') as fp:\n",
    "            for row in fp:\n",
    "                stop_word.append(row.strip())\n",
    "        stop_word = set(stop_word)\n",
    "        \n",
    "        return stop_word\n",
    "\n",
    "    def replaceCompositUnicode(self, str):\n",
    "        str = str.replace('à', 'à')\n",
    "        str = str.replace('ả', 'ả')\n",
    "        str = str.replace('ã', 'ã')\n",
    "        str = str.replace('á', 'á')\n",
    "        str = str.replace('ạ', 'ạ')\n",
    "        str = str.replace('ấ', 'ấ')\n",
    "        str = str.replace('ầ', 'ầ')\n",
    "        str = str.replace('ậ', 'ậ')\n",
    "        str = str.replace('ẩ', 'ẩ')\n",
    "        str = str.replace('ẫ', 'ẫ')\n",
    "        str = str.replace('ắ', 'ắ')\n",
    "        str = str.replace('ằ', 'ằ')\n",
    "        str = str.replace('ặ', 'ặ')\n",
    "        str = str.replace('ẳ', 'ẳ')\n",
    "        str = str.replace('ẵ', 'ẵ')\n",
    "        str = str.replace('è', 'è')\n",
    "        str = str.replace('ẻ', 'ẻ')\n",
    "        str = str.replace('ẽ', 'ẽ')\n",
    "        str = str.replace('é', 'é')\n",
    "        str = str.replace('ẹ', 'ẹ')\n",
    "        str = str.replace('ế', 'ế')\n",
    "        str = str.replace('ề', 'ề')\n",
    "        str = str.replace('ệ', 'ệ')\n",
    "        str = str.replace('ể', 'ể')\n",
    "        str = str.replace('ễ', 'ễ')\n",
    "        str = str.replace('ì', 'ì')\n",
    "        str = str.replace('ỉ', 'ỉ')\n",
    "        str = str.replace('ĩ', 'ĩ')\n",
    "        str = str.replace('í', 'í')\n",
    "        str = str.replace('ị', 'ị')\n",
    "        str = str.replace('ò', 'ò')\n",
    "        str = str.replace('ỏ', 'ỏ')\n",
    "        str = str.replace('õ', 'õ')\n",
    "        str = str.replace('ó', 'ó')\n",
    "        str = str.replace('ọ', 'ọ')\n",
    "        str = str.replace('ố', 'ố')\n",
    "        str = str.replace('ồ', 'ồ')\n",
    "        str = str.replace('ộ', 'ộ')\n",
    "        str = str.replace('ổ', 'ổ')\n",
    "        str = str.replace('ỗ', 'ỗ')\n",
    "        str = str.replace('ớ', 'ớ')\n",
    "        str = str.replace('ờ', 'ờ')\n",
    "        str = str.replace('ợ', 'ợ')\n",
    "        str = str.replace('ở', 'ở')\n",
    "        str = str.replace('ỡ', 'ỡ')\n",
    "        str = str.replace('ù', 'ù')\n",
    "        str = str.replace('ủ', 'ủ')\n",
    "        str = str.replace('ũ', 'ũ')\n",
    "        str = str.replace('ú', 'ú')\n",
    "        str = str.replace('ụ', 'ụ')\n",
    "        str = str.replace('ứ', 'ứ')\n",
    "        str = str.replace('ừ', 'ừ')\n",
    "        str = str.replace('ự', 'ự')\n",
    "        str = str.replace('ử', 'ử')\n",
    "        str = str.replace('ữ', 'ữ')\n",
    "        str = str.replace('ỳ', 'ỳ')\n",
    "        str = str.replace('ỷ', 'ỷ')\n",
    "        str = str.replace('ỹ', 'ỹ')\n",
    "        str = str.replace('ý', 'ý')\n",
    "        str = str.replace('ỵ', 'ỵ')\n",
    "        return str\n",
    "\n",
    "    def removeSpecialCharacter(self, str):\n",
    "        # Loai bo ki tu dac biet\n",
    "        str = re.sub(r'[^0-9a-zăâđêôơưàảãáạấầậẩẫắằặẳẵèẻẽéẹếềệểễìỉĩíịòỏõóọốồộổỗớờợởỡùủũúụứừựửữỳỷỹýỵ,\\s\\*]+', ' ',str)\n",
    "        # Xoa bo khoang trang dai\n",
    "        str = re.sub(' {2,}', ' ', str)\n",
    "        return str\n",
    "\n",
    "    def replaceAcronym(self, str):\n",
    "        # mot so tu viet tat\n",
    "        # 1*->1 sao, 2*-> 2 sao,...\n",
    "        str = re.sub('(^| )([0-9])\\*($| )', r'\\1sao\\2', str)\n",
    "        # 1sao -> 1 sao, 2sao -> 2 sao, ...\n",
    "        str = re.sub('(^| )([0-9])sao($| )', r'\\1sao\\2', str)\n",
    "        # * -> sao\n",
    "        str = re.sub(\"(^| )\\*($| )\", r\"\\1sao\\2\", str)\n",
    "        # s -> sao\n",
    "        str = re.sub(\"(^| )s($| )\", r\"\\1sao\\2\", str)\n",
    "        str = re.sub(\"(^| )sp($| )\", r\"\\1sản phẩm\\2\", str)\n",
    "        str = re.sub(\"(^| )rat($| )\", r\"\\1rất\\2\", str)\n",
    "        str = re.sub(\"(^| )dang($| )\", r\"\\1đáng\\2\", str)\n",
    "        str = re.sub(\"(^| )nhiu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )nhìu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )nhieu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )tot($| )\", r\"\\1tốt\\2\", str)\n",
    "        str = re.sub(\"(^| )tôt($| )\", r\"\\1tốt\\2\", str)\n",
    "        str = re.sub(\"(^| )muot($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )muọt($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )mươt($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )may($| )\", r\"\\1máy\\2\", str)\n",
    "        str = re.sub(\"(^| )tr($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )ae($| )\", r\"\\1anh em\\2\", str)\n",
    "        str = re.sub(\"(^| )đc($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )dc($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )dk($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )đk($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )k($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )ko($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )kg($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )kh($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )hk($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )khg($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )r($| )\", r\"\\1rồi\\2\", str)\n",
    "        str = re.sub(\"(^| )m($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mh($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mih($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mìh($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mk($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mik($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )bh($| )\", r\"\\1bao giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )h($| )\", r\"\\1giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )jo($| )\", r\"\\1giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )z($| )\", r\"\\1vậy\\2\", str)\n",
    "        str = re.sub(\"(^| )j($| )\", r\"\\1gì\\2\", str)\n",
    "        str = re.sub(\"(^| )cx($| )\", r\"\\1cũng\\2\", str)\n",
    "        str = re.sub(\"(^| )vs($| )\", r\"\\1với\\2\", str)\n",
    "        str = re.sub(\"(^| )ah($| )\", r\"\\1à\\2\", str)\n",
    "        str = re.sub(\"(^| )ak($| )\", r\"\\1à\\2\", str)\n",
    "        str = re.sub(\"(^| )ntn($| )\", r\"\\1như thế nào\\2\", str)\n",
    "        str = re.sub(\"(^| )lm($| )\", r\"\\1làm\\2\", str)\n",
    "        str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )t2($| )\", r\"\\1thứ 2\\2\", str)\n",
    "        str = re.sub(\"(^| )cn($| )\", r\"\\1chủ nhật\\2\", str)\n",
    "        str = re.sub(\"(^| )t3($| )\", r\"\\1thứ 3\\2\", str)\n",
    "        str = re.sub(\"(^| )t4($| )\", r\"\\1thứ 4\\2\", str)\n",
    "        str = re.sub(\"(^| )t5($| )\", r\"\\1thứ 5\\2\", str)\n",
    "        str = re.sub(\"(^| )t6($| )\", r\"\\1thứ 6\\2\", str)\n",
    "        str = re.sub(\"(^| )t7($| )\", r\"\\1thứ 7\\2\", str)\n",
    "        str = re.sub(\"(^| )mn($| )\", r\"\\1mọi người\\2\", str)\n",
    "        return str\n",
    "\n",
    "    def doPreprocess(self, str):\n",
    "        str = str.lower()\n",
    "        str = self.replaceCompositUnicode(str)\n",
    "        str = self.removeSpecialCharacter(str)\n",
    "        str = self.replaceAcronym(str)\n",
    "        # to lower case\n",
    "        \n",
    "        # number removing\n",
    "        str = re.sub(r'\\d+', '', str)\n",
    "        # remove punctuation\n",
    "#         str = str.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        # remove white spaces\n",
    "        str = str.strip()\n",
    "        str = re.sub(' +', ' ', str)\n",
    "        # # tokenize by pyvi\n",
    "        str = ViTokenizer.tokenize(str)\n",
    "        # # remove stopword\n",
    "        # str = str.split()\n",
    "        # str = [i for i in str if not i in self.stop_word]\n",
    "        # str = ' '.join(str)\n",
    "        return str\n",
    "\n",
    "    def balance_classes(self,xs, ys):\n",
    "        freqs = Counter(ys)\n",
    "        max_allowable = freqs.most_common()[-1][1]\n",
    "        num_added = {clss: 0 for clss in freqs.keys()}\n",
    "        new_ys = []\n",
    "        new_xs = []\n",
    "        for i, y in enumerate(ys):\n",
    "            if num_added[y] < max_allowable:\n",
    "                new_ys.append(y)\n",
    "                new_xs.append(xs[i])\n",
    "                num_added[y] += 1\n",
    "        return new_xs, new_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSVData(fileName):\n",
    "    star= []\n",
    "    review = []\n",
    "    p = Preprocess()\n",
    "    with open(fileName) as csv_file:\n",
    "        for row in csv_file:\n",
    "            row = row.split('<fff>')\n",
    "            star.append(row[0])\n",
    "            review.append(p.doPreprocess(row[1]))\n",
    "    review, star = p.balance_classes(review, star)\n",
    "    return review, star\n",
    "\n",
    "def readTXTData(fileName):\n",
    "    star = []\n",
    "    review = []\n",
    "    p = Preprocess()\n",
    "    with open(fileName, 'r') as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            star.append(line[0])\n",
    "            review.append(p.doPreprocess(line[2:]))\n",
    "            line = fp.readline()\n",
    "            \n",
    "    return review, star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, y1_train = readCSVData('data_final2.csv')\n",
    "x_test, y_test = readTXTData('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Counter({'5': 1033, '4': 987, '3': 976, '1': 968, '2': 961})\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "x_train = x1_train + x_test[:150]\n",
    "y_train = y1_train + y_test[:150]\n",
    "x_test = x_test[151:500]\n",
    "y_test = y_test[151:500]\n",
    "\n",
    "# print(len(x_train))\n",
    "from collections import Counter\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4069)\t0.30623593629369744\n",
      "  (0, 18294)\t0.30623593629369744\n",
      "  (0, 8006)\t0.30623593629369744\n",
      "  (0, 15084)\t0.30623593629369744\n",
      "  (0, 1778)\t0.2539490171985226\n",
      "  (0, 22931)\t0.23619095626439665\n",
      "  (0, 17546)\t0.2921405703577373\n",
      "  (0, 27074)\t0.2539490171985226\n",
      "  (0, 24343)\t0.23858938648967223\n",
      "  (0, 4067)\t0.2921405703577373\n",
      "  (0, 18286)\t0.18118095206708013\n",
      "  (0, 7996)\t0.2077436664028333\n",
      "  (0, 15081)\t0.22449402055371212\n",
      "  (0, 1708)\t0.12698941509915115\n",
      "  (0, 22918)\t0.12127463851027563\n",
      "  (0, 17507)\t0.14866714129864375\n",
      "  (0, 27053)\t0.18214666554969683\n",
      "  (1, 17779)\t0.4701450104779424\n",
      "  (1, 8391)\t0.5102978150078954\n",
      "  (1, 20068)\t0.4701450104779424\n",
      "  (1, 17772)\t0.4018675868604548\n",
      "  (1, 8381)\t0.3688169205371595\n",
      "  (2, 17558)\t0.16960052109234577\n",
      "  (2, 3116)\t0.21572462555756025\n",
      "  (2, 21736)\t0.25751723009597577\n",
      "  :\t:\n",
      "  (4922, 26196)\t0.2666349640003292\n",
      "  (4922, 7435)\t0.21097954169615996\n",
      "  (4922, 20359)\t0.182176996024895\n",
      "  (4922, 12005)\t0.1847782714414848\n",
      "  (4922, 26122)\t0.1390710845479176\n",
      "  (4922, 8738)\t0.16733039250338916\n",
      "  (4922, 29424)\t0.1339883436656218\n",
      "  (4922, 7393)\t0.1446910960958875\n",
      "  (4922, 21724)\t0.12582696038888064\n",
      "  (4923, 20339)\t0.469755655427022\n",
      "  (4923, 28354)\t0.5404025052711301\n",
      "  (4923, 29836)\t0.5404025052711301\n",
      "  (4923, 28331)\t0.38060925630153625\n",
      "  (4923, 20204)\t0.22449160965455411\n",
      "  (4924, 28093)\t0.3983965468632648\n",
      "  (4924, 1219)\t0.3983965468632648\n",
      "  (4924, 1217)\t0.3800592309243705\n",
      "  (4924, 29449)\t0.3417398583086523\n",
      "  (4924, 7451)\t0.3357008495620274\n",
      "  (4924, 21868)\t0.3072717804282221\n",
      "  (4924, 28087)\t0.31374357128885844\n",
      "  (4924, 25504)\t0.14895851636684135\n",
      "  (4924, 29424)\t0.17523305956285531\n",
      "  (4924, 7393)\t0.1892303671105898\n",
      "  (4924, 21724)\t0.1645594134625833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectors = vectorizer.fit_transform(x_train)\n",
    "print(vectors.toarra)\n",
    "vectors1 = vectorizer.transform(x_test)\n",
    "    #     return vectors\n",
    "\n",
    "    # def fit(self):\n",
    "        # vectors = self.tfidf()\n",
    "classifier = LinearSVC()\n",
    "        # train the classifier\n",
    "classifier.fit(vectors, y_train)\n",
    "        # return classifier\n",
    "vectors1 = vectorizer.transform(x_test)\n",
    "predict = classifier.predict(vectors1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac = accuracy_score(y_test, predict)\n",
    "# print(ac)\n",
    "# print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6275071633237822\n",
      "[[  3   5   3   2   5]\n",
      " [  0   4   1   1   2]\n",
      " [  0   1   7  13  19]\n",
      " [  0   1   6  56  24]\n",
      " [  0   2   4  41 149]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5616045845272206\n",
      "[[  0   0   0   0  18]\n",
      " [  0   0   0   0   8]\n",
      " [  0   0   0   0  40]\n",
      " [  0   0   0   0  87]\n",
      " [  0   0   0   0 196]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.1\n",
      "  (0, 2)\t0.2\n",
      "  (1, 2)\t0.3\n",
      "  (2, 0)\t0.4\n",
      "  (2, 1)\t0.5\n",
      "  (2, 2)\t0.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "aaaa = csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "print(aaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
