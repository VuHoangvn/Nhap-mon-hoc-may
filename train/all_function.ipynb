{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from pyvi import ViTokenizer, ViPosTagger, ViUtils\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        stop_word = []\n",
    "        with open('stopword.txt') as fp:\n",
    "            for row in fp:\n",
    "                stop_word.append(row.strip())\n",
    "        stop_word = set(stop_word)\n",
    "        self.stop_word = stop_word\n",
    "        return\n",
    "    @staticmethod\n",
    "    def readStopWord(self):\n",
    "        stop_word = []\n",
    "        with open('stopword.txt') as fp:\n",
    "            for row in fp:\n",
    "                stop_word.append(row.strip())\n",
    "        stop_word = set(stop_word)\n",
    "        \n",
    "        return stop_word\n",
    "\n",
    "    def replaceCompositUnicode(self, str):\n",
    "        str = str.replace('à', 'à')\n",
    "        str = str.replace('ả', 'ả')\n",
    "        str = str.replace('ã', 'ã')\n",
    "        str = str.replace('á', 'á')\n",
    "        str = str.replace('ạ', 'ạ')\n",
    "        str = str.replace('ấ', 'ấ')\n",
    "        str = str.replace('ầ', 'ầ')\n",
    "        str = str.replace('ậ', 'ậ')\n",
    "        str = str.replace('ẩ', 'ẩ')\n",
    "        str = str.replace('ẫ', 'ẫ')\n",
    "        str = str.replace('ắ', 'ắ')\n",
    "        str = str.replace('ằ', 'ằ')\n",
    "        str = str.replace('ặ', 'ặ')\n",
    "        str = str.replace('ẳ', 'ẳ')\n",
    "        str = str.replace('ẵ', 'ẵ')\n",
    "        str = str.replace('è', 'è')\n",
    "        str = str.replace('ẻ', 'ẻ')\n",
    "        str = str.replace('ẽ', 'ẽ')\n",
    "        str = str.replace('é', 'é')\n",
    "        str = str.replace('ẹ', 'ẹ')\n",
    "        str = str.replace('ế', 'ế')\n",
    "        str = str.replace('ề', 'ề')\n",
    "        str = str.replace('ệ', 'ệ')\n",
    "        str = str.replace('ể', 'ể')\n",
    "        str = str.replace('ễ', 'ễ')\n",
    "        str = str.replace('ì', 'ì')\n",
    "        str = str.replace('ỉ', 'ỉ')\n",
    "        str = str.replace('ĩ', 'ĩ')\n",
    "        str = str.replace('í', 'í')\n",
    "        str = str.replace('ị', 'ị')\n",
    "        str = str.replace('ò', 'ò')\n",
    "        str = str.replace('ỏ', 'ỏ')\n",
    "        str = str.replace('õ', 'õ')\n",
    "        str = str.replace('ó', 'ó')\n",
    "        str = str.replace('ọ', 'ọ')\n",
    "        str = str.replace('ố', 'ố')\n",
    "        str = str.replace('ồ', 'ồ')\n",
    "        str = str.replace('ộ', 'ộ')\n",
    "        str = str.replace('ổ', 'ổ')\n",
    "        str = str.replace('ỗ', 'ỗ')\n",
    "        str = str.replace('ớ', 'ớ')\n",
    "        str = str.replace('ờ', 'ờ')\n",
    "        str = str.replace('ợ', 'ợ')\n",
    "        str = str.replace('ở', 'ở')\n",
    "        str = str.replace('ỡ', 'ỡ')\n",
    "        str = str.replace('ù', 'ù')\n",
    "        str = str.replace('ủ', 'ủ')\n",
    "        str = str.replace('ũ', 'ũ')\n",
    "        str = str.replace('ú', 'ú')\n",
    "        str = str.replace('ụ', 'ụ')\n",
    "        str = str.replace('ứ', 'ứ')\n",
    "        str = str.replace('ừ', 'ừ')\n",
    "        str = str.replace('ự', 'ự')\n",
    "        str = str.replace('ử', 'ử')\n",
    "        str = str.replace('ữ', 'ữ')\n",
    "        str = str.replace('ỳ', 'ỳ')\n",
    "        str = str.replace('ỷ', 'ỷ')\n",
    "        str = str.replace('ỹ', 'ỹ')\n",
    "        str = str.replace('ý', 'ý')\n",
    "        str = str.replace('ỵ', 'ỵ')\n",
    "        return str\n",
    "\n",
    "    def removeSpecialCharacter(self, str):\n",
    "        # Loai bo ki tu dac biet\n",
    "        str = re.sub(r'[^0-9a-zăâđêôơưàảãáạấầậẩẫắằặẳẵèẻẽéẹếềệểễìỉĩíịòỏõóọốồộổỗớờợởỡùủũúụứừựửữỳỷỹýỵ,\\s\\*]+', ' ',str)\n",
    "        # Xoa bo khoang trang dai\n",
    "        str = re.sub(' {2,}', ' ', str)\n",
    "        return str\n",
    "\n",
    "    def replaceAcronym(self, str):\n",
    "        # mot so tu viet tat\n",
    "        # 1*->1 sao, 2*-> 2 sao,...\n",
    "        str = re.sub('(^| )([0-9])\\*($| )', r'\\1sao\\2', str)\n",
    "        # 1sao -> 1 sao, 2sao -> 2 sao, ...\n",
    "        str = re.sub('(^| )([0-9])sao($| )', r'\\1sao\\2', str)\n",
    "        # * -> sao\n",
    "        str = re.sub(\"(^| )\\*($| )\", r\"\\1sao\\2\", str)\n",
    "        # s -> sao\n",
    "        str = re.sub(\"(^| )s($| )\", r\"\\1sao\\2\", str)\n",
    "        str = re.sub(\"(^| )sp($| )\", r\"\\1sản phẩm\\2\", str)\n",
    "        str = re.sub(\"(^| )rat($| )\", r\"\\1rất\\2\", str)\n",
    "        str = re.sub(\"(^| )dang($| )\", r\"\\1đáng\\2\", str)\n",
    "        str = re.sub(\"(^| )nhiu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )nhìu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )nhieu($| )\", r\"\\1nhiều\\2\", str)\n",
    "        str = re.sub(\"(^| )tot($| )\", r\"\\1tốt\\2\", str)\n",
    "        str = re.sub(\"(^| )tôt($| )\", r\"\\1tốt\\2\", str)\n",
    "        str = re.sub(\"(^| )muot($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )muọt($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )mươt($| )\", r\"\\1mượt\\2\", str)\n",
    "        str = re.sub(\"(^| )may($| )\", r\"\\1máy\\2\", str)\n",
    "        str = re.sub(\"(^| )tr($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )ae($| )\", r\"\\1anh em\\2\", str)\n",
    "        str = re.sub(\"(^| )đc($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )dc($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )dk($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )đk($| )\", r\"\\1được\\2\", str)\n",
    "        str = re.sub(\"(^| )k($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )ko($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )kg($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )kh($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )hk($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )khg($| )\", r\"\\1không\\2\", str)\n",
    "        str = re.sub(\"(^| )r($| )\", r\"\\1rồi\\2\", str)\n",
    "        str = re.sub(\"(^| )m($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mh($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mih($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mìh($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mk($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )mik($| )\", r\"\\1mình\\2\", str)\n",
    "        str = re.sub(\"(^| )bh($| )\", r\"\\1bao giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )h($| )\", r\"\\1giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )jo($| )\", r\"\\1giờ\\2\", str)\n",
    "        str = re.sub(\"(^| )z($| )\", r\"\\1vậy\\2\", str)\n",
    "        str = re.sub(\"(^| )j($| )\", r\"\\1gì\\2\", str)\n",
    "        str = re.sub(\"(^| )cx($| )\", r\"\\1cũng\\2\", str)\n",
    "        str = re.sub(\"(^| )vs($| )\", r\"\\1với\\2\", str)\n",
    "        str = re.sub(\"(^| )ah($| )\", r\"\\1à\\2\", str)\n",
    "        str = re.sub(\"(^| )ak($| )\", r\"\\1à\\2\", str)\n",
    "        str = re.sub(\"(^| )ntn($| )\", r\"\\1như thế nào\\2\", str)\n",
    "        str = re.sub(\"(^| )lm($| )\", r\"\\1làm\\2\", str)\n",
    "        str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "        str = re.sub(\"(^| )t2($| )\", r\"\\1thứ 2\\2\", str)\n",
    "        str = re.sub(\"(^| )cn($| )\", r\"\\1chủ nhật\\2\", str)\n",
    "        str = re.sub(\"(^| )t3($| )\", r\"\\1thứ 3\\2\", str)\n",
    "        str = re.sub(\"(^| )t4($| )\", r\"\\1thứ 4\\2\", str)\n",
    "        str = re.sub(\"(^| )t5($| )\", r\"\\1thứ 5\\2\", str)\n",
    "        str = re.sub(\"(^| )t6($| )\", r\"\\1thứ 6\\2\", str)\n",
    "        str = re.sub(\"(^| )t7($| )\", r\"\\1thứ 7\\2\", str)\n",
    "        str = re.sub(\"(^| )mn($| )\", r\"\\1mọi người\\2\", str)\n",
    "        return str\n",
    "\n",
    "    def doPreprocess(self, str):\n",
    "        str = str.lower()\n",
    "        str = self.replaceCompositUnicode(str)\n",
    "        str = self.removeSpecialCharacter(str)\n",
    "        str = self.replaceAcronym(str)\n",
    "        # to lower case\n",
    "        \n",
    "        # number removing\n",
    "        str = re.sub(r'\\d+', '', str)\n",
    "        # remove punctuation\n",
    "#         str = str.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        # remove white spaces\n",
    "        str = str.strip()\n",
    "        str = re.sub(' +', ' ', str)\n",
    "        # # tokenize by pyvi\n",
    "        str = ViTokenizer.tokenize(str)\n",
    "        # # remove stopword\n",
    "        # str = str.split()\n",
    "        # str = [i for i in str if not i in self.stop_word]\n",
    "        # str = ' '.join(str)\n",
    "        return str\n",
    "\n",
    "    def balance_classes(self,xs, ys):\n",
    "        freqs = Counter(ys)\n",
    "        max_allowable = freqs.most_common()[-1][1]\n",
    "        num_added = {clss: 0 for clss in freqs.keys()}\n",
    "        new_ys = []\n",
    "        new_xs = []\n",
    "        for i, y in enumerate(ys):\n",
    "            if num_added[y] < max_allowable:\n",
    "                new_ys.append(y)\n",
    "                new_xs.append(xs[i])\n",
    "                num_added[y] += 1\n",
    "        return new_xs, new_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSVData(fileName):\n",
    "    star= []\n",
    "    review = []\n",
    "    p = Preprocess()\n",
    "    with open(fileName) as csv_file:\n",
    "        for row in csv_file:\n",
    "            row = row.split('<fff>')\n",
    "            star.append(row[0])\n",
    "            review.append(p.doPreprocess(row[1]))\n",
    "    review, star = p.balance_classes(review, star)\n",
    "    return review, star\n",
    "\n",
    "def readTXTData(fileName):\n",
    "    star = []\n",
    "    review = []\n",
    "    p = Preprocess()\n",
    "    with open(fileName, 'r') as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            star.append(line[0])\n",
    "            review.append(p.doPreprocess(line[2:]))\n",
    "            line = fp.readline()\n",
    "            \n",
    "    return review, star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, y1_train = readCSVData('data_final2.csv')\n",
    "x_test, y_test = readTXTData('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Counter({'5': 1033, '4': 987, '3': 976, '1': 968, '2': 961})\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "x_train = x1_train + x_test[:150]\n",
    "y_train = y1_train + y_test[:150]\n",
    "x_test = x_test[151:500]\n",
    "y_test = y_test[151:500]\n",
    "\n",
    "# print(len(x_train))\n",
    "from collections import Counter\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6790830945558739\n",
      "[[  9   3   3   0   3]\n",
      " [  1   6   1   0   0]\n",
      " [  0   2  23  10   5]\n",
      " [  0   3   9  57  18]\n",
      " [  1   4   6  43 142]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectors = vectorizer.fit_transform(x_train)\n",
    "vectors1 = vectorizer.transform(x_test)\n",
    "    #     return vectors\n",
    "\n",
    "    # def fit(self):\n",
    "        # vectors = self.tfidf()\n",
    "classifier = LinearSVC()\n",
    "        # train the classifier\n",
    "classifier.fit(vectors, y_train)\n",
    "        # return classifier\n",
    "vectors1 = vectorizer.transform(x_test)\n",
    "predict = classifier.predict(vectors1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac = accuracy_score(y_test, predict)\n",
    "print(ac)\n",
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6275071633237822\n",
      "[[  3   5   3   2   5]\n",
      " [  0   4   1   1   2]\n",
      " [  0   1   7  13  19]\n",
      " [  0   1   6  56  24]\n",
      " [  0   2   4  41 149]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5616045845272206\n",
      "[[  0   0   0   0  18]\n",
      " [  0   0   0   0   8]\n",
      " [  0   0   0   0  40]\n",
      " [  0   0   0   0  87]\n",
      " [  0   0   0   0 196]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
