{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyvi import ViTokenizer, ViPosTagger, ViUtils\n",
    "# from CocCocTokenizer import PyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = []\n",
    "with open('stopword.txt') as fp:\n",
    "    for row in fp:\n",
    "        stop_word.append(row.strip())\n",
    "stop_word = set(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceCompositUnicode(str):\n",
    "    str = str.replace('à', 'à')\n",
    "    str = str.replace('ả', 'ả')\n",
    "    str = str.replace('ã', 'ã')\n",
    "    str = str.replace('á', 'á')\n",
    "    str = str.replace('ạ', 'ạ')\n",
    "    str = str.replace('ấ', 'ấ')\n",
    "    str = str.replace('ầ', 'ầ')\n",
    "    str = str.replace('ậ', 'ậ')\n",
    "    str = str.replace('ẩ', 'ẩ')\n",
    "    str = str.replace('ẫ', 'ẫ')\n",
    "    str = str.replace('ắ', 'ắ')\n",
    "    str = str.replace('ằ', 'ằ')\n",
    "    str = str.replace('ặ', 'ặ')\n",
    "    str = str.replace('ẳ', 'ẳ')\n",
    "    str = str.replace('ẵ', 'ẵ')\n",
    "    str = str.replace('è', 'è')\n",
    "    str = str.replace('ẻ', 'ẻ')\n",
    "    str = str.replace('ẽ', 'ẽ')\n",
    "    str = str.replace('é', 'é')\n",
    "    str = str.replace('ẹ', 'ẹ')\n",
    "    str = str.replace('ế', 'ế')\n",
    "    str = str.replace('ề', 'ề')\n",
    "    str = str.replace('ệ', 'ệ')\n",
    "    str = str.replace('ể', 'ể')\n",
    "    str = str.replace('ễ', 'ễ')\n",
    "    str = str.replace('ì', 'ì')\n",
    "    str = str.replace('ỉ', 'ỉ')\n",
    "    str = str.replace('ĩ', 'ĩ')\n",
    "    str = str.replace('í', 'í')\n",
    "    str = str.replace('ị', 'ị')\n",
    "    str = str.replace('ò', 'ò')\n",
    "    str = str.replace('ỏ', 'ỏ')\n",
    "    str = str.replace('õ', 'õ')\n",
    "    str = str.replace('ó', 'ó')\n",
    "    str = str.replace('ọ', 'ọ')\n",
    "    str = str.replace('ố', 'ố')\n",
    "    str = str.replace('ồ', 'ồ')\n",
    "    str = str.replace('ộ', 'ộ')\n",
    "    str = str.replace('ổ', 'ổ')\n",
    "    str = str.replace('ỗ', 'ỗ')\n",
    "    str = str.replace('ớ', 'ớ')\n",
    "    str = str.replace('ờ', 'ờ')\n",
    "    str = str.replace('ợ', 'ợ')\n",
    "    str = str.replace('ở', 'ở')\n",
    "    str = str.replace('ỡ', 'ỡ')\n",
    "    str = str.replace('ù', 'ù')\n",
    "    str = str.replace('ủ', 'ủ')\n",
    "    str = str.replace('ũ', 'ũ')\n",
    "    str = str.replace('ú', 'ú')\n",
    "    str = str.replace('ụ', 'ụ')\n",
    "    str = str.replace('ứ', 'ứ')\n",
    "    str = str.replace('ừ', 'ừ')\n",
    "    str = str.replace('ự', 'ự')\n",
    "    str = str.replace('ử', 'ử')\n",
    "    str = str.replace('ữ', 'ữ')\n",
    "    str = str.replace('ỳ', 'ỳ')\n",
    "    str = str.replace('ỷ', 'ỷ')\n",
    "    str = str.replace('ỹ', 'ỹ')\n",
    "    str = str.replace('ý', 'ý')\n",
    "    str = str.replace('ỵ', 'ỵ')\n",
    "    return str\n",
    "\n",
    "def removeSpecialCharacter(str):\n",
    "    # Loai bo ki tu dac biet\n",
    "    str = re.sub(r'[^0-9a-zăâđêôơưàảãáạấầậẩẫắằặẳẵèẻẽéẹếềệểễìỉĩíịòỏõóọốồộổỗớờợởỡùủũúụứừựửữỳỷỹýỵ,\\s\\*]+', ' ',str)\n",
    "    # Xoa bo khoang trang dai\n",
    "    str = re.sub(' {2,}', ' ', str)\n",
    "    return str\n",
    "\n",
    "def replaceAcronym(str):\n",
    "    # mot so tu viet tat\n",
    "    # 1*->1 sao, 2*-> 2 sao,...\n",
    "    str = re.sub('(^| )([0-9])\\*($| )', r'\\1sao\\2', str)\n",
    "    # 1sao -> 1 sao, 2sao -> 2 sao, ...\n",
    "    str = re.sub('(^| )([0-9])sao($| )', r'\\1sao\\2', str)\n",
    "    # * -> sao\n",
    "    str = re.sub(\"(^| )\\*($| )\", r\"\\1sao\\2\", str)\n",
    "    # s -> sao\n",
    "    str = re.sub(\"(^| )s($| )\", r\"\\1sao\\2\", str)\n",
    "    str = re.sub(\"(^| )sp($| )\", r\"\\1sản phẩm\\2\", str)\n",
    "    str = re.sub(\"(^| )rat($| )\", r\"\\1rất\\2\", str)\n",
    "    str = re.sub(\"(^| )dang($| )\", r\"\\1đáng\\2\", str)\n",
    "    str = re.sub(\"(^| )nhiu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )nhìu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )nhieu($| )\", r\"\\1nhiều\\2\", str)\n",
    "    str = re.sub(\"(^| )tot($| )\", r\"\\1tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )tôt($| )\", r\"\\1tốt\\2\", str)\n",
    "    str = re.sub(\"(^| )muot($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )muọt($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )mươt($| )\", r\"\\1mượt\\2\", str)\n",
    "    str = re.sub(\"(^| )may($| )\", r\"\\1máy\\2\", str)\n",
    "    str = re.sub(\"(^| )tr($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )ae($| )\", r\"\\1anh em\\2\", str)\n",
    "    str = re.sub(\"(^| )đc($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )dc($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )dk($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )đk($| )\", r\"\\1được\\2\", str)\n",
    "    str = re.sub(\"(^| )k($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )ko($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )kg($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )kh($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )hk($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )khg($| )\", r\"\\1không\\2\", str)\n",
    "    str = re.sub(\"(^| )r($| )\", r\"\\1rồi\\2\", str)\n",
    "    str = re.sub(\"(^| )m($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mh($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mih($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mìh($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mk($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )mik($| )\", r\"\\1mình\\2\", str)\n",
    "    str = re.sub(\"(^| )bh($| )\", r\"\\1bao giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )h($| )\", r\"\\1giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )jo($| )\", r\"\\1giờ\\2\", str)\n",
    "    str = re.sub(\"(^| )z($| )\", r\"\\1vậy\\2\", str)\n",
    "    str = re.sub(\"(^| )j($| )\", r\"\\1gì\\2\", str)\n",
    "    str = re.sub(\"(^| )cx($| )\", r\"\\1cũng\\2\", str)\n",
    "    str = re.sub(\"(^| )vs($| )\", r\"\\1với\\2\", str)\n",
    "    str = re.sub(\"(^| )ah($| )\", r\"\\1à\\2\", str)\n",
    "    str = re.sub(\"(^| )ak($| )\", r\"\\1à\\2\", str)\n",
    "    str = re.sub(\"(^| )ntn($| )\", r\"\\1như thế nào\\2\", str)\n",
    "    str = re.sub(\"(^| )lm($| )\", r\"\\1làm\\2\", str)\n",
    "    str = re.sub(\"(^| )trc($| )\", r\"\\1trước\\2\", str)\n",
    "    str = re.sub(\"(^| )t2($| )\", r\"\\1thứ 2\\2\", str)\n",
    "    str = re.sub(\"(^| )cn($| )\", r\"\\1chủ nhật\\2\", str)\n",
    "    str = re.sub(\"(^| )t3($| )\", r\"\\1thứ 3\\2\", str)\n",
    "    str = re.sub(\"(^| )t4($| )\", r\"\\1thứ 4\\2\", str)\n",
    "    str = re.sub(\"(^| )t5($| )\", r\"\\1thứ 5\\2\", str)\n",
    "    str = re.sub(\"(^| )t6($| )\", r\"\\1thứ 6\\2\", str)\n",
    "    str = re.sub(\"(^| )t7($| )\", r\"\\1thứ 7\\2\", str)\n",
    "    str = re.sub(\"(^| )mn($| )\", r\"\\1mọi người\\2\", str)\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "def preprocess(str):\n",
    "    # to lower case\n",
    "    str = str.lower()\n",
    "    \n",
    "    # to remove number\n",
    "#     str = re.sub(r'\\d+','', str)\n",
    "    # remove punctuation\n",
    "    str = str.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    # remove white spaces\n",
    "    str = str.strip()\n",
    "    str = re.sub(' +', ' ', str)\n",
    "#     str = replaceCompositUnicode(str)\n",
    "#     str = removeSpecialCharacter(str)\n",
    "#     str = replaceAcronym(str)\n",
    "    # tokenize by pyvi\n",
    "    str = ViTokenizer.tokenize(str)\n",
    "#     str = unidecode(str)\n",
    "    \n",
    "    # tokenize by nltk\n",
    "#     tknzr = TweetTokenizer()\n",
    "#     str = tknzr.tokenize(str)\n",
    "#     print(str)\n",
    "    # # remove stopword\n",
    "#     str = str.split()\n",
    "#     str = [i for i in str if not i in stop_word]\n",
    "#     str = ' '.join(str)\n",
    "    return str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(xs, ys):\n",
    "    freqs = Counter(ys)\n",
    "    max_allowable = freqs.most_common()[-1][1]\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "star= []\n",
    "review = []\n",
    "# with open('data_final2.csv') as csv_file:\n",
    "#     for row in csv_file:\n",
    "#         row = row.split('<fff>')\n",
    "#         star.append(row[0])\n",
    "#         review.append(preprocess(row[1]))\n",
    "\n",
    "with open('train.txt', 'r') as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        star.append(line[0])\n",
    "        review.append(preprocess(line[2:]))\n",
    "        line = fp.readline()\n",
    "with open('bag_text.txt', 'r') as csv_file:\n",
    "    i = 0\n",
    "    for row in csv_file:\n",
    "        row = row.split('<fff>')\n",
    "        star.append(row[0])\n",
    "        review.append(preprocess(row[1]))\n",
    "        i += 1\n",
    "#         print(i)\n",
    "        if(i == 3000):\n",
    "            break\n",
    "# for i in range(1, 5):\n",
    "#     filename = \"{}_star.txt\".format(i)\n",
    "#     with open(filename, 'r') as fp:\n",
    "#         line = fp.readline()\n",
    "#         while line:\n",
    "#             star.append('{}'.format(i))\n",
    "#             review.append(preprocess(line))\n",
    "#             line = fp.readline()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review, star = balance_classes(review, star)\n",
    "X_train, X_test, y_train, y_test = train_test_split(review, star, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'3': 139, '4': 306, '5': 1049, '1': 106, '2': 64})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630937880633374\n",
      "[[  3   0   1   7  41]\n",
      " [  1   0   0   2  19]\n",
      " [  0   0   4  10  63]\n",
      " [  0   0   1  23 147]\n",
      " [  0   0   0  11 488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#Train and evaluate the model\n",
    "# vect = CountVectorizer().fit(X_train)\n",
    "vect = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "clfrNB = MultinomialNB(alpha = 0.1)\n",
    "clfrNB.fit(X_train_vectorized, y_train)\n",
    "preds = clfrNB.predict(vect.transform(X_test))\n",
    "score = accuracy_score(y_test, preds)\n",
    "print(score)\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
